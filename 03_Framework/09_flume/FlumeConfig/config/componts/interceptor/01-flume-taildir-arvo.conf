# Flume多路复用
# 读取一个日志，根据event中header的key-value，分类发送给两个agent

a1.sources = r1
a1.channels = c1 c2 c3
a1.sinks = k1 k2 k3

# Describe/configure the source
a1.sources.r1.type = TAILDIR
a1.sources.r1.positionFile = /opt/module/flume/jobs/tail_dir.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/flume/datas/xiaodong.log

# 配置channel selector 多路复用
a1.sources.r1.selector.type = multiplexing
# event中header中的key是type
a1.sources.r1.selector.header = type
# event中header的key是“type”，如果值是“number”，发送到c1
a1.sources.r1.selector.mapping.number = c1
# event中header的key是“type”，如果值是“else”，发送到c1
a1.sources.r1.selector.mapping.else = c2
# event不满足以上映射条件的，默认发送到c3 channel
a1.sources.r1.selector.default = c3

# 自定义拦截器
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = cn.xiaodong.flume.components.interceptor.CustomInterceptor$Builder

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100

a1.channels.c3.type = memory
a1.channels.c3.capacity = 1000
a1.channels.c3.transactionCapacity = 100


# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop102
a1.sinks.k1.port = 4444

a1.sinks.k2.type = avro
a1.sinks.k2.hostname = hadoop102
a1.sinks.k2.port = 5555

a1.sinks.k3.type = avro
a1.sinks.k3.hostname = hadoop102
a1.sinks.k3.port = 6666

# Bind the source and sink to the channel
# 一个source对接两个channel
a1.sources.r1.channels = c1 c2 c3
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2
a1.sinks.k3.channel = c3
